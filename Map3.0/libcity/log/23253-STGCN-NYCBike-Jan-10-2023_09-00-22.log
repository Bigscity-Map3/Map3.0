2023-01-10 09:00:22,152 - INFO - Log directory: ./libcity/log
2023-01-10 09:00:22,154 - INFO - Begin pipeline, task=traffic_state_pred, model_name=STGCN, dataset_name=NYCBike, exp_id=23253
2023-01-10 09:00:22,154 - INFO - {'task': 'traffic_state_pred', 'model': 'STGCN', 'dataset': 'NYCBike', 'saved_model': True, 'train': True, 'seed': 0, 'dataset_class': 'TrafficStateGridDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'Ks': 3, 'Kt': 3, 'blocks': [[1, 32, 64], [64, 32, 128]], 'dropout': 0, 'graph_conv_type': 'chebconv', 'stgcn_train_mode': 'full', 'bidir_adj_mx': True, 'scaler': 'standard', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'max_epoch': 100, 'learner': 'rmsprop', 'learning_rate': 0.001, 'lr_decay': True, 'lr_scheduler': 'steplr', 'lr_decay_ratio': 0.7, 'step_size': 5, 'clip_grad_norm': False, 'use_early_stop': False, 'batch_size': 32, 'cache_dataset': True, 'num_workers': 1, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 19, 'output_window': 1, 'use_row_column': True, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'max_grad_norm': 1.0, 'patience': 50, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {'row_id': 'num', 'column_id': 'num'}}, 'grid': {'including_types': ['state'], 'state': {'row_id': 16, 'column_id': 8, 'new_flow': 'num', 'end_flow': 'num'}}, 'data_col': ['new_flow', 'end_flow'], 'data_files': ['NYCBIKE20140409'], 'geo_file': 'NYCBIKE20140409', 'output_dim': 2, 'time_intervals': 3600, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'device': device(type='cuda', index=0), 'exp_id': 23253}
2023-01-10 09:00:22,174 - INFO - Loaded file NYCBIKE20140409.geo, num_grids=128, grid_size=(16, 8)
2023-01-10 09:00:22,175 - INFO - Generate grid rel file, shape=(128, 128)
2023-01-10 09:00:22,175 - INFO - Loading file NYCBIKE20140409.grid
2023-01-10 09:00:22,522 - INFO - Loaded file NYCBIKE20140409.grid, shape=(4392, 16, 8, 2)
2023-01-10 09:00:22,840 - INFO - Dataset created
2023-01-10 09:00:22,840 - INFO - x shape: (4373, 19, 16, 8, 2), y shape: (4373, 1, 16, 8, 2)
2023-01-10 09:00:22,841 - INFO - train	x: (3061, 19, 16, 8, 2), y: (3061, 1, 16, 8, 2)
2023-01-10 09:00:22,841 - INFO - eval	x: (437, 19, 16, 8, 2), y: (437, 1, 16, 8, 2)
2023-01-10 09:00:22,841 - INFO - test	x: (875, 19, 16, 8, 2), y: (875, 1, 16, 8, 2)
2023-01-10 09:00:27,972 - INFO - Saved at ./libcity/cache/dataset_cache/grid_based_NYCBike_19_1_0.7_0.1_standard_32_False_False_False_True_True.npz
2023-01-10 09:00:28,060 - INFO - StandardScaler mean: 9.23899494542977, std: 18.095629608758927
2023-01-10 09:00:28,060 - INFO - NoneScaler
2023-01-10 09:00:28,346 - INFO - You select full mode to train STGCN model.
2023-01-10 09:00:28,486 - INFO - Chebyshev_polynomial_Lk shape: (3, 128, 128)
2023-01-10 09:00:33,260 - INFO - STGCN(
  (st_conv1): STConvBlock(
    (tconv1): TemporalConvLayer(
      (align): Align()
      (conv): Conv2d(2, 64, kernel_size=(3, 1), stride=(1, 1))
    )
    (sconv): SpatioConvLayer(
      (align): Align()
    )
    (tconv2): TemporalConvLayer(
      (align): Align()
      (conv): Conv2d(32, 64, kernel_size=(3, 1), stride=(1, 1))
    )
    (ln): LayerNorm((128, 64), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (st_conv2): STConvBlock(
    (tconv1): TemporalConvLayer(
      (align): Align(
        (conv1x1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      )
      (conv): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1))
    )
    (sconv): SpatioConvLayer(
      (align): Align()
    )
    (tconv2): TemporalConvLayer(
      (align): Align()
      (conv): Conv2d(32, 128, kernel_size=(3, 1), stride=(1, 1))
    )
    (ln): LayerNorm((128, 128), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (output): OutputLayer(
    (tconv1): TemporalConvLayer(
      (align): Align()
      (conv): Conv2d(128, 256, kernel_size=(11, 1), stride=(1, 1))
    )
    (ln): LayerNorm((128, 128), eps=1e-05, elementwise_affine=True)
    (tconv2): TemporalConvLayer(
      (align): Align()
      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (fc): FullyConvLayer(
      (conv): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
2023-01-10 09:00:33,261 - INFO - st_conv1.tconv1.conv.weight	torch.Size([64, 2, 3, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.tconv1.conv.bias	torch.Size([64])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.sconv.theta	torch.Size([32, 32, 3])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.sconv.b	torch.Size([1, 32, 1, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.tconv2.conv.weight	torch.Size([64, 32, 3, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.tconv2.conv.bias	torch.Size([64])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.ln.weight	torch.Size([128, 64])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv1.ln.bias	torch.Size([128, 64])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv1.align.conv1x1.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv1.align.conv1x1.bias	torch.Size([32])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv1.conv.weight	torch.Size([64, 64, 3, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv1.conv.bias	torch.Size([64])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.sconv.theta	torch.Size([32, 32, 3])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.sconv.b	torch.Size([1, 32, 1, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv2.conv.weight	torch.Size([128, 32, 3, 1])	cuda:0	True
2023-01-10 09:00:33,261 - INFO - st_conv2.tconv2.conv.bias	torch.Size([128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - st_conv2.ln.weight	torch.Size([128, 128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - st_conv2.ln.bias	torch.Size([128, 128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.tconv1.conv.weight	torch.Size([256, 128, 11, 1])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.tconv1.conv.bias	torch.Size([256])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.ln.weight	torch.Size([128, 128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.ln.bias	torch.Size([128, 128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.tconv2.conv.weight	torch.Size([128, 128, 1, 1])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.tconv2.conv.bias	torch.Size([128])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.fc.conv.weight	torch.Size([2, 128, 1, 1])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - output.fc.conv.bias	torch.Size([2])	cuda:0	True
2023-01-10 09:00:33,262 - INFO - Total parameter numbers: 499106
2023-01-10 09:00:33,262 - INFO - You select `rmsprop` optimizer.
2023-01-10 09:00:33,262 - INFO - You select `steplr` lr_scheduler.
2023-01-10 09:00:33,263 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-01-10 09:00:33,263 - INFO - Start training ...
2023-01-10 09:00:33,263 - INFO - num_batches:96
2023-01-10 09:00:35,199 - INFO - epoch complete!
2023-01-10 09:00:35,200 - INFO - 1.93617844581604
2023-01-10 09:00:35,200 - INFO - evaluating now!
2023-01-10 09:00:35,495 - INFO - Epoch [0/100] train_loss: 108.1278, val_loss: 79.4161, lr: 0.001000, 2.23s
2023-01-10 09:00:35,508 - INFO - Saved model at 0
2023-01-10 09:00:35,508 - INFO - Val loss decrease from inf to 79.4161, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch0.tar
2023-01-10 09:00:37,433 - INFO - epoch complete!
2023-01-10 09:00:37,434 - INFO - 1.9250729084014893
2023-01-10 09:00:37,434 - INFO - evaluating now!
2023-01-10 09:00:37,719 - INFO - Epoch [1/100] train_loss: 46.2241, val_loss: 39.9271, lr: 0.001000, 2.21s
2023-01-10 09:00:37,730 - INFO - Saved model at 1
2023-01-10 09:00:37,730 - INFO - Val loss decrease from 79.4161 to 39.9271, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch1.tar
2023-01-10 09:00:39,543 - INFO - epoch complete!
2023-01-10 09:00:39,544 - INFO - 1.8122994899749756
2023-01-10 09:00:39,544 - INFO - evaluating now!
2023-01-10 09:00:39,833 - INFO - Epoch [2/100] train_loss: 37.4075, val_loss: 38.5432, lr: 0.001000, 2.10s
2023-01-10 09:00:39,845 - INFO - Saved model at 2
2023-01-10 09:00:39,846 - INFO - Val loss decrease from 39.9271 to 38.5432, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch2.tar
2023-01-10 09:00:41,634 - INFO - epoch complete!
2023-01-10 09:00:41,635 - INFO - 1.787780523300171
2023-01-10 09:00:41,635 - INFO - evaluating now!
2023-01-10 09:00:41,918 - INFO - Epoch [3/100] train_loss: 32.9346, val_loss: 45.1493, lr: 0.001000, 2.07s
2023-01-10 09:00:43,782 - INFO - epoch complete!
2023-01-10 09:00:43,782 - INFO - 1.8627965450286865
2023-01-10 09:00:43,782 - INFO - evaluating now!
2023-01-10 09:00:44,076 - INFO - Epoch [4/100] train_loss: 31.7900, val_loss: 39.4218, lr: 0.000700, 2.16s
2023-01-10 09:00:46,047 - INFO - epoch complete!
2023-01-10 09:00:46,048 - INFO - 1.9709734916687012
2023-01-10 09:00:46,048 - INFO - evaluating now!
2023-01-10 09:00:46,361 - INFO - Epoch [5/100] train_loss: 26.4550, val_loss: 28.4986, lr: 0.000700, 2.29s
2023-01-10 09:00:46,377 - INFO - Saved model at 5
2023-01-10 09:00:46,377 - INFO - Val loss decrease from 38.5432 to 28.4986, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch5.tar
2023-01-10 09:00:48,302 - INFO - epoch complete!
2023-01-10 09:00:48,303 - INFO - 1.9247734546661377
2023-01-10 09:00:48,303 - INFO - evaluating now!
2023-01-10 09:00:48,603 - INFO - Epoch [6/100] train_loss: 25.8077, val_loss: 27.0766, lr: 0.000700, 2.23s
2023-01-10 09:00:48,617 - INFO - Saved model at 6
2023-01-10 09:00:48,617 - INFO - Val loss decrease from 28.4986 to 27.0766, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch6.tar
2023-01-10 09:00:50,446 - INFO - epoch complete!
2023-01-10 09:00:50,447 - INFO - 1.8283979892730713
2023-01-10 09:00:50,447 - INFO - evaluating now!
2023-01-10 09:00:50,759 - INFO - Epoch [7/100] train_loss: 25.3762, val_loss: 26.3757, lr: 0.000700, 2.14s
2023-01-10 09:00:50,771 - INFO - Saved model at 7
2023-01-10 09:00:50,771 - INFO - Val loss decrease from 27.0766 to 26.3757, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch7.tar
2023-01-10 09:00:52,647 - INFO - epoch complete!
2023-01-10 09:00:52,648 - INFO - 1.8759124279022217
2023-01-10 09:00:52,648 - INFO - evaluating now!
2023-01-10 09:00:52,942 - INFO - Epoch [8/100] train_loss: 24.4479, val_loss: 26.5159, lr: 0.000700, 2.17s
2023-01-10 09:00:54,784 - INFO - epoch complete!
2023-01-10 09:00:54,785 - INFO - 1.8414638042449951
2023-01-10 09:00:54,785 - INFO - evaluating now!
2023-01-10 09:00:55,074 - INFO - Epoch [9/100] train_loss: 23.5038, val_loss: 27.4873, lr: 0.000490, 2.13s
2023-01-10 09:00:56,983 - INFO - epoch complete!
2023-01-10 09:00:56,984 - INFO - 1.9083716869354248
2023-01-10 09:00:56,984 - INFO - evaluating now!
2023-01-10 09:00:57,274 - INFO - Epoch [10/100] train_loss: 21.7189, val_loss: 26.3127, lr: 0.000490, 2.20s
2023-01-10 09:00:57,285 - INFO - Saved model at 10
2023-01-10 09:00:57,286 - INFO - Val loss decrease from 26.3757 to 26.3127, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch10.tar
2023-01-10 09:00:59,164 - INFO - epoch complete!
2023-01-10 09:00:59,164 - INFO - 1.8778049945831299
2023-01-10 09:00:59,164 - INFO - evaluating now!
2023-01-10 09:00:59,458 - INFO - Epoch [11/100] train_loss: 21.4492, val_loss: 25.0563, lr: 0.000490, 2.17s
2023-01-10 09:00:59,469 - INFO - Saved model at 11
2023-01-10 09:00:59,470 - INFO - Val loss decrease from 26.3127 to 25.0563, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch11.tar
2023-01-10 09:01:01,358 - INFO - epoch complete!
2023-01-10 09:01:01,359 - INFO - 1.8884270191192627
2023-01-10 09:01:01,359 - INFO - evaluating now!
2023-01-10 09:01:01,670 - INFO - Epoch [12/100] train_loss: 21.1366, val_loss: 24.1233, lr: 0.000490, 2.20s
2023-01-10 09:01:01,683 - INFO - Saved model at 12
2023-01-10 09:01:01,684 - INFO - Val loss decrease from 25.0563 to 24.1233, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch12.tar
2023-01-10 09:01:03,558 - INFO - epoch complete!
2023-01-10 09:01:03,559 - INFO - 1.8741943836212158
2023-01-10 09:01:03,559 - INFO - evaluating now!
2023-01-10 09:01:03,855 - INFO - Epoch [13/100] train_loss: 21.1466, val_loss: 25.9815, lr: 0.000490, 2.17s
2023-01-10 09:01:05,749 - INFO - epoch complete!
2023-01-10 09:01:05,749 - INFO - 1.8935108184814453
2023-01-10 09:01:05,750 - INFO - evaluating now!
2023-01-10 09:01:06,040 - INFO - Epoch [14/100] train_loss: 20.3241, val_loss: 25.7221, lr: 0.000343, 2.18s
2023-01-10 09:01:07,971 - INFO - epoch complete!
2023-01-10 09:01:07,972 - INFO - 1.930800437927246
2023-01-10 09:01:07,972 - INFO - evaluating now!
2023-01-10 09:01:08,253 - INFO - Epoch [15/100] train_loss: 19.2248, val_loss: 23.2615, lr: 0.000343, 2.21s
2023-01-10 09:01:08,267 - INFO - Saved model at 15
2023-01-10 09:01:08,267 - INFO - Val loss decrease from 24.1233 to 23.2615, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch15.tar
2023-01-10 09:01:10,074 - INFO - epoch complete!
2023-01-10 09:01:10,075 - INFO - 1.8062903881072998
2023-01-10 09:01:10,075 - INFO - evaluating now!
2023-01-10 09:01:10,370 - INFO - Epoch [16/100] train_loss: 19.0598, val_loss: 23.5952, lr: 0.000343, 2.10s
2023-01-10 09:01:12,260 - INFO - epoch complete!
2023-01-10 09:01:12,261 - INFO - 1.8897290229797363
2023-01-10 09:01:12,261 - INFO - evaluating now!
2023-01-10 09:01:12,564 - INFO - Epoch [17/100] train_loss: 18.9887, val_loss: 23.6069, lr: 0.000343, 2.19s
2023-01-10 09:01:14,351 - INFO - epoch complete!
2023-01-10 09:01:14,351 - INFO - 1.7858250141143799
2023-01-10 09:01:14,352 - INFO - evaluating now!
2023-01-10 09:01:14,650 - INFO - Epoch [18/100] train_loss: 18.7001, val_loss: 24.3585, lr: 0.000343, 2.09s
2023-01-10 09:01:16,488 - INFO - epoch complete!
2023-01-10 09:01:16,489 - INFO - 1.8367745876312256
2023-01-10 09:01:16,489 - INFO - evaluating now!
2023-01-10 09:01:16,773 - INFO - Epoch [19/100] train_loss: 18.5446, val_loss: 23.2653, lr: 0.000240, 2.12s
2023-01-10 09:01:18,699 - INFO - epoch complete!
2023-01-10 09:01:18,700 - INFO - 1.925114393234253
2023-01-10 09:01:18,700 - INFO - evaluating now!
2023-01-10 09:01:18,994 - INFO - Epoch [20/100] train_loss: 17.8293, val_loss: 23.2056, lr: 0.000240, 2.22s
2023-01-10 09:01:19,006 - INFO - Saved model at 20
2023-01-10 09:01:19,006 - INFO - Val loss decrease from 23.2615 to 23.2056, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch20.tar
2023-01-10 09:01:20,943 - INFO - epoch complete!
2023-01-10 09:01:20,943 - INFO - 1.936171531677246
2023-01-10 09:01:20,944 - INFO - evaluating now!
2023-01-10 09:01:21,260 - INFO - Epoch [21/100] train_loss: 17.4935, val_loss: 23.1461, lr: 0.000240, 2.25s
2023-01-10 09:01:21,274 - INFO - Saved model at 21
2023-01-10 09:01:21,274 - INFO - Val loss decrease from 23.2056 to 23.1461, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch21.tar
2023-01-10 09:01:23,226 - INFO - epoch complete!
2023-01-10 09:01:23,227 - INFO - 1.9512965679168701
2023-01-10 09:01:23,227 - INFO - evaluating now!
2023-01-10 09:01:23,526 - INFO - Epoch [22/100] train_loss: 17.4656, val_loss: 22.8429, lr: 0.000240, 2.25s
2023-01-10 09:01:23,540 - INFO - Saved model at 22
2023-01-10 09:01:23,540 - INFO - Val loss decrease from 23.1461 to 22.8429, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch22.tar
2023-01-10 09:01:25,398 - INFO - epoch complete!
2023-01-10 09:01:25,399 - INFO - 1.857466220855713
2023-01-10 09:01:25,399 - INFO - evaluating now!
2023-01-10 09:01:25,693 - INFO - Epoch [23/100] train_loss: 17.3574, val_loss: 24.1036, lr: 0.000240, 2.15s
2023-01-10 09:01:27,559 - INFO - epoch complete!
2023-01-10 09:01:27,560 - INFO - 1.8652265071868896
2023-01-10 09:01:27,560 - INFO - evaluating now!
2023-01-10 09:01:27,861 - INFO - Epoch [24/100] train_loss: 17.0993, val_loss: 22.9033, lr: 0.000168, 2.17s
2023-01-10 09:01:29,735 - INFO - epoch complete!
2023-01-10 09:01:29,735 - INFO - 1.8730320930480957
2023-01-10 09:01:29,735 - INFO - evaluating now!
2023-01-10 09:01:30,041 - INFO - Epoch [25/100] train_loss: 16.6102, val_loss: 22.6527, lr: 0.000168, 2.18s
2023-01-10 09:01:30,053 - INFO - Saved model at 25
2023-01-10 09:01:30,053 - INFO - Val loss decrease from 22.8429 to 22.6527, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch25.tar
2023-01-10 09:01:31,916 - INFO - epoch complete!
2023-01-10 09:01:31,917 - INFO - 1.8628685474395752
2023-01-10 09:01:31,917 - INFO - evaluating now!
2023-01-10 09:01:32,219 - INFO - Epoch [26/100] train_loss: 16.5201, val_loss: 22.6325, lr: 0.000168, 2.17s
2023-01-10 09:01:32,231 - INFO - Saved model at 26
2023-01-10 09:01:32,231 - INFO - Val loss decrease from 22.6527 to 22.6325, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch26.tar
2023-01-10 09:01:34,096 - INFO - epoch complete!
2023-01-10 09:01:34,097 - INFO - 1.864461898803711
2023-01-10 09:01:34,097 - INFO - evaluating now!
2023-01-10 09:01:34,390 - INFO - Epoch [27/100] train_loss: 16.4143, val_loss: 22.4273, lr: 0.000168, 2.16s
2023-01-10 09:01:34,405 - INFO - Saved model at 27
2023-01-10 09:01:34,405 - INFO - Val loss decrease from 22.6325 to 22.4273, saving to ./libcity/cache/23253/model_cache/STGCN_NYCBike_epoch27.tar
2023-01-10 09:01:36,255 - INFO - epoch complete!
2023-01-10 09:01:36,256 - INFO - 1.8497569561004639
2023-01-10 09:01:36,256 - INFO - evaluating now!
2023-01-10 09:01:36,530 - INFO - Epoch [28/100] train_loss: 16.3586, val_loss: 22.4744, lr: 0.000168, 2.12s
2023-01-10 09:01:38,374 - INFO - epoch complete!
2023-01-10 09:01:38,375 - INFO - 1.8436944484710693
2023-01-10 09:01:38,375 - INFO - evaluating now!
2023-01-10 09:01:38,679 - INFO - Epoch [29/100] train_loss: 16.1521, val_loss: 22.7795, lr: 0.000118, 2.15s
2023-01-10 09:01:40,543 - INFO - epoch complete!
2023-01-10 09:01:40,544 - INFO - 1.8635661602020264
2023-01-10 09:01:40,544 - INFO - evaluating now!
2023-01-10 09:01:40,843 - INFO - Epoch [30/100] train_loss: 15.8771, val_loss: 22.9041, lr: 0.000118, 2.16s
2023-01-10 09:01:42,744 - INFO - epoch complete!
2023-01-10 09:01:42,745 - INFO - 1.9007463455200195
2023-01-10 09:01:42,745 - INFO - evaluating now!
2023-01-10 09:01:43,041 - INFO - Epoch [31/100] train_loss: 15.8286, val_loss: 22.5239, lr: 0.000118, 2.20s
2023-01-10 09:01:44,883 - INFO - epoch complete!
2023-01-10 09:01:44,884 - INFO - 1.841162919998169
2023-01-10 09:01:44,884 - INFO - evaluating now!
2023-01-10 09:01:45,182 - INFO - Epoch [32/100] train_loss: 15.6961, val_loss: 22.6526, lr: 0.000118, 2.14s
2023-01-10 09:01:47,109 - INFO - epoch complete!
2023-01-10 09:01:47,109 - INFO - 1.9261670112609863
2023-01-10 09:01:47,110 - INFO - evaluating now!
2023-01-10 09:01:47,423 - INFO - Epoch [33/100] train_loss: 15.6691, val_loss: 22.7547, lr: 0.000118, 2.24s
2023-01-10 09:01:49,352 - INFO - epoch complete!
2023-01-10 09:01:49,353 - INFO - 1.928832769393921
2023-01-10 09:01:49,353 - INFO - evaluating now!
2023-01-10 09:01:49,660 - INFO - Epoch [34/100] train_loss: 15.5753, val_loss: 22.5582, lr: 0.000082, 2.24s
2023-01-10 09:01:51,546 - INFO - epoch complete!
2023-01-10 09:01:51,547 - INFO - 1.8854670524597168
2023-01-10 09:01:51,547 - INFO - evaluating now!
2023-01-10 09:01:51,845 - INFO - Epoch [35/100] train_loss: 15.3097, val_loss: 22.5492, lr: 0.000082, 2.18s
2023-01-10 09:01:53,748 - INFO - epoch complete!
2023-01-10 09:01:53,748 - INFO - 1.901498794555664
2023-01-10 09:01:53,748 - INFO - evaluating now!
2023-01-10 09:01:54,045 - INFO - Epoch [36/100] train_loss: 15.3012, val_loss: 22.5847, lr: 0.000082, 2.20s
2023-01-10 09:01:56,009 - INFO - epoch complete!
2023-01-10 09:01:56,010 - INFO - 1.9634926319122314
2023-01-10 09:01:56,010 - INFO - evaluating now!
2023-01-10 09:01:56,309 - INFO - Epoch [37/100] train_loss: 15.2101, val_loss: 22.4631, lr: 0.000082, 2.26s
2023-01-10 09:01:58,148 - INFO - epoch complete!
2023-01-10 09:01:58,148 - INFO - 1.8376169204711914
2023-01-10 09:01:58,148 - INFO - evaluating now!
2023-01-10 09:01:58,443 - INFO - Epoch [38/100] train_loss: 15.1278, val_loss: 22.6327, lr: 0.000082, 2.13s
2023-01-10 09:02:00,297 - INFO - epoch complete!
2023-01-10 09:02:00,298 - INFO - 1.8538188934326172
2023-01-10 09:02:00,298 - INFO - evaluating now!
2023-01-10 09:02:00,577 - INFO - Epoch [39/100] train_loss: 15.0905, val_loss: 22.5188, lr: 0.000058, 2.13s
2023-01-10 09:02:02,485 - INFO - epoch complete!
2023-01-10 09:02:02,486 - INFO - 1.9071180820465088
2023-01-10 09:02:02,486 - INFO - evaluating now!
2023-01-10 09:02:02,773 - INFO - Epoch [40/100] train_loss: 14.9318, val_loss: 22.4997, lr: 0.000058, 2.19s
2023-01-10 09:02:04,784 - INFO - epoch complete!
2023-01-10 09:02:04,785 - INFO - 2.0107598304748535
2023-01-10 09:02:04,785 - INFO - evaluating now!
2023-01-10 09:02:05,091 - INFO - Epoch [41/100] train_loss: 14.9134, val_loss: 22.5600, lr: 0.000058, 2.32s
2023-01-10 09:02:06,964 - INFO - epoch complete!
2023-01-10 09:02:06,965 - INFO - 1.8720638751983643
2023-01-10 09:02:06,965 - INFO - evaluating now!
2023-01-10 09:02:07,261 - INFO - Epoch [42/100] train_loss: 14.8322, val_loss: 22.5614, lr: 0.000058, 2.17s
2023-01-10 09:02:09,215 - INFO - epoch complete!
2023-01-10 09:02:09,215 - INFO - 1.9533729553222656
2023-01-10 09:02:09,215 - INFO - evaluating now!
2023-01-10 09:02:09,533 - INFO - Epoch [43/100] train_loss: 14.8335, val_loss: 22.6102, lr: 0.000058, 2.27s
2023-01-10 09:02:11,447 - INFO - epoch complete!
2023-01-10 09:02:11,447 - INFO - 1.9125251770019531
2023-01-10 09:02:11,447 - INFO - evaluating now!
2023-01-10 09:02:11,759 - INFO - Epoch [44/100] train_loss: 14.7344, val_loss: 22.5952, lr: 0.000040, 2.23s
2023-01-10 09:02:13,653 - INFO - epoch complete!
2023-01-10 09:02:13,654 - INFO - 1.8926143646240234
2023-01-10 09:02:13,654 - INFO - evaluating now!
2023-01-10 09:02:13,957 - INFO - Epoch [45/100] train_loss: 14.6535, val_loss: 22.5275, lr: 0.000040, 2.20s
2023-01-10 09:02:15,848 - INFO - epoch complete!
2023-01-10 09:02:15,848 - INFO - 1.8897929191589355
2023-01-10 09:02:15,849 - INFO - evaluating now!
2023-01-10 09:02:16,162 - INFO - Epoch [46/100] train_loss: 14.6161, val_loss: 22.6473, lr: 0.000040, 2.20s
2023-01-10 09:02:18,150 - INFO - epoch complete!
2023-01-10 09:02:18,151 - INFO - 1.9872264862060547
2023-01-10 09:02:18,151 - INFO - evaluating now!
2023-01-10 09:02:18,470 - INFO - Epoch [47/100] train_loss: 14.5855, val_loss: 22.6548, lr: 0.000040, 2.31s
2023-01-10 09:02:20,425 - INFO - epoch complete!
2023-01-10 09:02:20,426 - INFO - 1.9549205303192139
2023-01-10 09:02:20,426 - INFO - evaluating now!
2023-01-10 09:02:20,713 - INFO - Epoch [48/100] train_loss: 14.5534, val_loss: 22.6220, lr: 0.000040, 2.24s
2023-01-10 09:02:22,617 - INFO - epoch complete!
2023-01-10 09:02:22,618 - INFO - 1.9031462669372559
2023-01-10 09:02:22,618 - INFO - evaluating now!
2023-01-10 09:02:22,912 - INFO - Epoch [49/100] train_loss: 14.5301, val_loss: 22.6963, lr: 0.000028, 2.20s
2023-01-10 09:02:24,820 - INFO - epoch complete!
2023-01-10 09:02:24,820 - INFO - 1.9063444137573242
2023-01-10 09:02:24,820 - INFO - evaluating now!
2023-01-10 09:02:25,132 - INFO - Epoch [50/100] train_loss: 14.4630, val_loss: 22.6351, lr: 0.000028, 2.22s
2023-01-10 09:02:27,075 - INFO - epoch complete!
2023-01-10 09:02:27,076 - INFO - 1.942009449005127
2023-01-10 09:02:27,076 - INFO - evaluating now!
2023-01-10 09:02:27,381 - INFO - Epoch [51/100] train_loss: 14.4386, val_loss: 22.6419, lr: 0.000028, 2.25s
2023-01-10 09:02:29,262 - INFO - epoch complete!
2023-01-10 09:02:29,262 - INFO - 1.8794474601745605
2023-01-10 09:02:29,262 - INFO - evaluating now!
2023-01-10 09:02:29,558 - INFO - Epoch [52/100] train_loss: 14.4125, val_loss: 22.6143, lr: 0.000028, 2.18s
2023-01-10 09:02:31,495 - INFO - epoch complete!
2023-01-10 09:02:31,495 - INFO - 1.9357857704162598
2023-01-10 09:02:31,496 - INFO - evaluating now!
2023-01-10 09:02:31,864 - INFO - Epoch [53/100] train_loss: 14.3793, val_loss: 22.6425, lr: 0.000028, 2.30s
2023-01-10 09:02:33,857 - INFO - epoch complete!
2023-01-10 09:02:33,857 - INFO - 1.992293357849121
2023-01-10 09:02:33,858 - INFO - evaluating now!
2023-01-10 09:02:34,182 - INFO - Epoch [54/100] train_loss: 14.3712, val_loss: 22.6301, lr: 0.000020, 2.32s
2023-01-10 09:02:36,118 - INFO - epoch complete!
2023-01-10 09:02:36,118 - INFO - 1.9342563152313232
2023-01-10 09:02:36,118 - INFO - evaluating now!
2023-01-10 09:02:36,419 - INFO - Epoch [55/100] train_loss: 14.2965, val_loss: 22.6651, lr: 0.000020, 2.24s
2023-01-10 09:02:38,490 - INFO - epoch complete!
2023-01-10 09:02:38,490 - INFO - 2.0701522827148438
2023-01-10 09:02:38,490 - INFO - evaluating now!
2023-01-10 09:02:38,811 - INFO - Epoch [56/100] train_loss: 14.3019, val_loss: 22.6479, lr: 0.000020, 2.39s
2023-01-10 09:02:40,829 - INFO - epoch complete!
2023-01-10 09:02:40,829 - INFO - 2.017418622970581
2023-01-10 09:02:40,830 - INFO - evaluating now!
2023-01-10 09:02:41,144 - INFO - Epoch [57/100] train_loss: 14.2743, val_loss: 22.7487, lr: 0.000020, 2.33s
2023-01-10 09:02:43,070 - INFO - epoch complete!
2023-01-10 09:02:43,070 - INFO - 1.924567699432373
2023-01-10 09:02:43,070 - INFO - evaluating now!
2023-01-10 09:02:43,368 - INFO - Epoch [58/100] train_loss: 14.2642, val_loss: 22.7942, lr: 0.000020, 2.22s
2023-01-10 09:02:45,196 - INFO - epoch complete!
2023-01-10 09:02:45,197 - INFO - 1.8276252746582031
2023-01-10 09:02:45,197 - INFO - evaluating now!
2023-01-10 09:02:45,499 - INFO - Epoch [59/100] train_loss: 14.2547, val_loss: 22.6632, lr: 0.000014, 2.13s
2023-01-10 09:02:47,489 - INFO - epoch complete!
2023-01-10 09:02:47,489 - INFO - 1.988640546798706
2023-01-10 09:02:47,490 - INFO - evaluating now!
2023-01-10 09:02:47,790 - INFO - Epoch [60/100] train_loss: 14.2092, val_loss: 22.6727, lr: 0.000014, 2.29s
2023-01-10 09:02:49,778 - INFO - epoch complete!
2023-01-10 09:02:49,779 - INFO - 1.9867076873779297
2023-01-10 09:02:49,779 - INFO - evaluating now!
2023-01-10 09:02:50,092 - INFO - Epoch [61/100] train_loss: 14.1978, val_loss: 22.6617, lr: 0.000014, 2.30s
2023-01-10 09:02:52,056 - INFO - epoch complete!
2023-01-10 09:02:52,057 - INFO - 1.963381052017212
2023-01-10 09:02:52,057 - INFO - evaluating now!
2023-01-10 09:02:52,368 - INFO - Epoch [62/100] train_loss: 14.1927, val_loss: 22.6623, lr: 0.000014, 2.28s
2023-01-10 09:02:54,380 - INFO - epoch complete!
2023-01-10 09:02:54,384 - INFO - 2.011232852935791
2023-01-10 09:02:54,384 - INFO - evaluating now!
2023-01-10 09:02:54,694 - INFO - Epoch [63/100] train_loss: 14.1798, val_loss: 22.6759, lr: 0.000014, 2.33s
2023-01-10 09:02:56,608 - INFO - epoch complete!
2023-01-10 09:02:56,608 - INFO - 1.9127607345581055
2023-01-10 09:02:56,608 - INFO - evaluating now!
2023-01-10 09:02:56,911 - INFO - Epoch [64/100] train_loss: 14.1680, val_loss: 22.7725, lr: 0.000010, 2.22s
2023-01-10 09:02:58,854 - INFO - epoch complete!
2023-01-10 09:02:58,855 - INFO - 1.9426259994506836
2023-01-10 09:02:58,855 - INFO - evaluating now!
2023-01-10 09:02:59,171 - INFO - Epoch [65/100] train_loss: 14.1400, val_loss: 22.7202, lr: 0.000010, 2.26s
2023-01-10 09:03:01,140 - INFO - epoch complete!
2023-01-10 09:03:01,141 - INFO - 1.9672977924346924
2023-01-10 09:03:01,141 - INFO - evaluating now!
2023-01-10 09:03:01,454 - INFO - Epoch [66/100] train_loss: 14.1262, val_loss: 22.7374, lr: 0.000010, 2.28s
2023-01-10 09:03:03,478 - INFO - epoch complete!
2023-01-10 09:03:03,479 - INFO - 2.023083209991455
2023-01-10 09:03:03,479 - INFO - evaluating now!
2023-01-10 09:03:03,784 - INFO - Epoch [67/100] train_loss: 14.1222, val_loss: 22.7043, lr: 0.000010, 2.33s
2023-01-10 09:03:05,755 - INFO - epoch complete!
2023-01-10 09:03:05,756 - INFO - 1.9699780941009521
2023-01-10 09:03:05,756 - INFO - evaluating now!
2023-01-10 09:03:06,051 - INFO - Epoch [68/100] train_loss: 14.1172, val_loss: 22.7056, lr: 0.000010, 2.27s
2023-01-10 09:03:08,015 - INFO - epoch complete!
2023-01-10 09:03:08,016 - INFO - 1.9635529518127441
2023-01-10 09:03:08,016 - INFO - evaluating now!
2023-01-10 09:03:08,342 - INFO - Epoch [69/100] train_loss: 14.1057, val_loss: 22.7194, lr: 0.000007, 2.29s
2023-01-10 09:03:10,418 - INFO - epoch complete!
2023-01-10 09:03:10,419 - INFO - 2.075782537460327
2023-01-10 09:03:10,419 - INFO - evaluating now!
2023-01-10 09:03:10,731 - INFO - Epoch [70/100] train_loss: 14.0874, val_loss: 22.7237, lr: 0.000007, 2.39s
2023-01-10 09:03:12,759 - INFO - epoch complete!
2023-01-10 09:03:12,760 - INFO - 2.0275461673736572
2023-01-10 09:03:12,760 - INFO - evaluating now!
2023-01-10 09:03:13,063 - INFO - Epoch [71/100] train_loss: 14.0798, val_loss: 22.7355, lr: 0.000007, 2.33s
2023-01-10 09:03:15,080 - INFO - epoch complete!
2023-01-10 09:03:15,081 - INFO - 2.0155346393585205
2023-01-10 09:03:15,081 - INFO - evaluating now!
2023-01-10 09:03:15,398 - INFO - Epoch [72/100] train_loss: 14.0773, val_loss: 22.7249, lr: 0.000007, 2.33s
2023-01-10 09:03:17,541 - INFO - epoch complete!
2023-01-10 09:03:17,542 - INFO - 2.142550468444824
2023-01-10 09:03:17,542 - INFO - evaluating now!
2023-01-10 09:03:17,847 - INFO - Epoch [73/100] train_loss: 14.0706, val_loss: 22.7251, lr: 0.000007, 2.45s
2023-01-10 09:03:19,943 - INFO - epoch complete!
2023-01-10 09:03:19,944 - INFO - 2.0954253673553467
2023-01-10 09:03:19,944 - INFO - evaluating now!
2023-01-10 09:03:20,269 - INFO - Epoch [74/100] train_loss: 14.0698, val_loss: 22.7286, lr: 0.000005, 2.42s
2023-01-10 09:03:22,330 - INFO - epoch complete!
2023-01-10 09:03:22,330 - INFO - 2.0603606700897217
2023-01-10 09:03:22,331 - INFO - evaluating now!
2023-01-10 09:03:22,627 - INFO - Epoch [75/100] train_loss: 14.0525, val_loss: 22.7318, lr: 0.000005, 2.36s
2023-01-10 09:03:24,662 - INFO - epoch complete!
2023-01-10 09:03:24,662 - INFO - 2.0338339805603027
2023-01-10 09:03:24,662 - INFO - evaluating now!
2023-01-10 09:03:25,027 - INFO - Epoch [76/100] train_loss: 14.0497, val_loss: 22.7341, lr: 0.000005, 2.40s
2023-01-10 09:03:27,037 - INFO - epoch complete!
2023-01-10 09:03:27,038 - INFO - 2.0094432830810547
2023-01-10 09:03:27,038 - INFO - evaluating now!
2023-01-10 09:03:27,375 - INFO - Epoch [77/100] train_loss: 14.0443, val_loss: 22.7343, lr: 0.000005, 2.35s
2023-01-10 09:03:29,346 - INFO - epoch complete!
2023-01-10 09:03:29,347 - INFO - 1.9704766273498535
2023-01-10 09:03:29,347 - INFO - evaluating now!
2023-01-10 09:03:29,640 - INFO - Epoch [78/100] train_loss: 14.0412, val_loss: 22.7333, lr: 0.000005, 2.26s
2023-01-10 09:03:31,602 - INFO - epoch complete!
2023-01-10 09:03:31,602 - INFO - 1.9604837894439697
2023-01-10 09:03:31,602 - INFO - evaluating now!
2023-01-10 09:03:31,901 - INFO - Epoch [79/100] train_loss: 14.0363, val_loss: 22.7330, lr: 0.000003, 2.26s
2023-01-10 09:03:33,844 - INFO - epoch complete!
2023-01-10 09:03:33,844 - INFO - 1.9415385723114014
2023-01-10 09:03:33,844 - INFO - evaluating now!
2023-01-10 09:03:34,142 - INFO - Epoch [80/100] train_loss: 14.0268, val_loss: 22.7386, lr: 0.000003, 2.24s
2023-01-10 09:03:36,168 - INFO - epoch complete!
2023-01-10 09:03:36,169 - INFO - 2.0251059532165527
2023-01-10 09:03:36,169 - INFO - evaluating now!
2023-01-10 09:03:36,485 - INFO - Epoch [81/100] train_loss: 14.0252, val_loss: 22.7330, lr: 0.000003, 2.34s
2023-01-10 09:03:38,404 - INFO - epoch complete!
2023-01-10 09:03:38,404 - INFO - 1.917788028717041
2023-01-10 09:03:38,405 - INFO - evaluating now!
2023-01-10 09:03:38,697 - INFO - Epoch [82/100] train_loss: 14.0209, val_loss: 22.7428, lr: 0.000003, 2.21s
2023-01-10 09:03:40,642 - INFO - epoch complete!
2023-01-10 09:03:40,643 - INFO - 1.9442615509033203
2023-01-10 09:03:40,643 - INFO - evaluating now!
2023-01-10 09:03:40,954 - INFO - Epoch [83/100] train_loss: 14.0181, val_loss: 22.7407, lr: 0.000003, 2.26s
2023-01-10 09:03:42,861 - INFO - epoch complete!
2023-01-10 09:03:42,862 - INFO - 1.9055092334747314
2023-01-10 09:03:42,862 - INFO - evaluating now!
2023-01-10 09:03:43,170 - INFO - Epoch [84/100] train_loss: 14.0161, val_loss: 22.7403, lr: 0.000002, 2.21s
2023-01-10 09:03:45,117 - INFO - epoch complete!
2023-01-10 09:03:45,118 - INFO - 1.9459083080291748
2023-01-10 09:03:45,118 - INFO - evaluating now!
2023-01-10 09:03:45,397 - INFO - Epoch [85/100] train_loss: 14.0088, val_loss: 22.7490, lr: 0.000002, 2.23s
2023-01-10 09:03:47,401 - INFO - epoch complete!
2023-01-10 09:03:47,402 - INFO - 2.0041298866271973
2023-01-10 09:03:47,402 - INFO - evaluating now!
2023-01-10 09:03:47,721 - INFO - Epoch [86/100] train_loss: 14.0068, val_loss: 22.7495, lr: 0.000002, 2.32s
2023-01-10 09:03:49,717 - INFO - epoch complete!
2023-01-10 09:03:49,717 - INFO - 1.9942817687988281
2023-01-10 09:03:49,717 - INFO - evaluating now!
2023-01-10 09:03:50,017 - INFO - Epoch [87/100] train_loss: 14.0044, val_loss: 22.7490, lr: 0.000002, 2.30s
2023-01-10 09:03:51,846 - INFO - epoch complete!
2023-01-10 09:03:51,847 - INFO - 1.828202247619629
2023-01-10 09:03:51,847 - INFO - evaluating now!
2023-01-10 09:03:52,142 - INFO - Epoch [88/100] train_loss: 14.0022, val_loss: 22.7496, lr: 0.000002, 2.12s
2023-01-10 09:03:54,046 - INFO - epoch complete!
2023-01-10 09:03:54,046 - INFO - 1.9025683403015137
2023-01-10 09:03:54,046 - INFO - evaluating now!
2023-01-10 09:03:54,352 - INFO - Epoch [89/100] train_loss: 14.0016, val_loss: 22.7510, lr: 0.000002, 2.21s
2023-01-10 09:03:56,350 - INFO - epoch complete!
2023-01-10 09:03:56,350 - INFO - 1.997093677520752
2023-01-10 09:03:56,351 - INFO - evaluating now!
2023-01-10 09:03:56,638 - INFO - Epoch [90/100] train_loss: 13.9964, val_loss: 22.7515, lr: 0.000002, 2.29s
2023-01-10 09:03:58,528 - INFO - epoch complete!
2023-01-10 09:03:58,529 - INFO - 1.8892405033111572
2023-01-10 09:03:58,529 - INFO - evaluating now!
2023-01-10 09:03:58,834 - INFO - Epoch [91/100] train_loss: 13.9942, val_loss: 22.7524, lr: 0.000002, 2.20s
2023-01-10 09:04:00,825 - INFO - epoch complete!
2023-01-10 09:04:00,826 - INFO - 1.989551067352295
2023-01-10 09:04:00,827 - INFO - evaluating now!
2023-01-10 09:04:01,126 - INFO - Epoch [92/100] train_loss: 13.9930, val_loss: 22.7515, lr: 0.000002, 2.29s
2023-01-10 09:04:03,056 - INFO - epoch complete!
2023-01-10 09:04:03,056 - INFO - 1.9282994270324707
2023-01-10 09:04:03,056 - INFO - evaluating now!
2023-01-10 09:04:03,358 - INFO - Epoch [93/100] train_loss: 13.9916, val_loss: 22.7534, lr: 0.000002, 2.23s
2023-01-10 09:04:05,375 - INFO - epoch complete!
2023-01-10 09:04:05,376 - INFO - 2.0159695148468018
2023-01-10 09:04:05,376 - INFO - evaluating now!
2023-01-10 09:04:05,679 - INFO - Epoch [94/100] train_loss: 13.9905, val_loss: 22.7527, lr: 0.000001, 2.32s
2023-01-10 09:04:07,548 - INFO - epoch complete!
2023-01-10 09:04:07,548 - INFO - 1.867570400238037
2023-01-10 09:04:07,549 - INFO - evaluating now!
2023-01-10 09:04:07,841 - INFO - Epoch [95/100] train_loss: 13.9871, val_loss: 22.7539, lr: 0.000001, 2.16s
2023-01-10 09:04:09,749 - INFO - epoch complete!
2023-01-10 09:04:09,749 - INFO - 1.9072082042694092
2023-01-10 09:04:09,749 - INFO - evaluating now!
2023-01-10 09:04:10,034 - INFO - Epoch [96/100] train_loss: 13.9855, val_loss: 22.7512, lr: 0.000001, 2.19s
2023-01-10 09:04:12,001 - INFO - epoch complete!
2023-01-10 09:04:12,002 - INFO - 1.9658968448638916
2023-01-10 09:04:12,002 - INFO - evaluating now!
2023-01-10 09:04:12,315 - INFO - Epoch [97/100] train_loss: 13.9853, val_loss: 22.7550, lr: 0.000001, 2.28s
2023-01-10 09:04:14,337 - INFO - epoch complete!
2023-01-10 09:04:14,337 - INFO - 2.020627021789551
2023-01-10 09:04:14,338 - INFO - evaluating now!
2023-01-10 09:04:14,644 - INFO - Epoch [98/100] train_loss: 13.9839, val_loss: 22.7560, lr: 0.000001, 2.33s
2023-01-10 09:04:16,557 - INFO - epoch complete!
2023-01-10 09:04:16,557 - INFO - 1.9116945266723633
2023-01-10 09:04:16,557 - INFO - evaluating now!
2023-01-10 09:04:16,847 - INFO - Epoch [99/100] train_loss: 13.9834, val_loss: 22.7577, lr: 0.000001, 2.20s
2023-01-10 09:04:16,848 - INFO - Trained totally 100 epochs, average train time is 1.929s, average eval time is 0.303s
2023-01-10 09:04:16,867 - INFO - Loaded model at 27
2023-01-10 09:04:16,868 - INFO - Saved model at ./libcity/cache/23253/model_cache/STGCN_NYCBike.m
2023-01-10 09:04:16,880 - INFO - Start evaluating ...
